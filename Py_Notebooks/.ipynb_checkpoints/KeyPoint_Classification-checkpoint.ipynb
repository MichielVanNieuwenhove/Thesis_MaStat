{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "890e1953-4664-4865-96d4-8aafa1941d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "26669a37-d9d0-48fd-9998-b10d17b14030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "SEED = 42\n",
    "num_classes = 2\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed057f9-9d09-44e3-adb7-71d382892513",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b6d977b-0a29-4281-9040-ce720168320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kp_labeled = pd.read_feather('../Data/TrainingData/df_kp_labeled.feather')\n",
    "df_kp_unlabeled = pd.read_feather('../Data/TrainingData/df_kp_unlabeled.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f067021d-8fea-4926-a041-c20f1f469eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID_kp  ID_dta                                          KEY_POINT  \\\n",
      "0      6      50  Stress stemmed from the fear of disease progre...   \n",
      "1      8      50   Not psychologically prepared to manage such s...   \n",
      "2     16      54  Not psychologically prepared to manage these s...   \n",
      "3     24      60  Stopping treatment was seen as a sign of recov...   \n",
      "4     35      68  The expertise of GPs familiar with Crohn's cou...   \n",
      "\n",
      "                                KEY_POINT_normalized  ID_kp_distinct  label  \n",
      "0  stress stemmed from the fear of disease progre...               3      1  \n",
      "1  not psychologically prepared to manage such so...               5      0  \n",
      "2  not psychologically prepared to manage these s...              11      0  \n",
      "3  stopping treatment was seen as a sign of recov...              16      1  \n",
      "4  the expertise of gps familiar with crohn's cou...              26      1  \n"
     ]
    }
   ],
   "source": [
    "print(df_kp_labeled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2167b604-ef4c-4775-9742-af5f20c61010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 0 to 18\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   ID_kp                 19 non-null     int32 \n",
      " 1   ID_dta                19 non-null     int32 \n",
      " 2   KEY_POINT             19 non-null     object\n",
      " 3   KEY_POINT_normalized  19 non-null     object\n",
      " 4   ID_kp_distinct        19 non-null     int64 \n",
      " 5   label                 19 non-null     int64 \n",
      "dtypes: int32(2), int64(2), object(2)\n",
      "memory usage: 888.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_kp_labeled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f6d688-7aec-4813-a519-eae755755412",
   "metadata": {},
   "source": [
    "# Importing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "14e13c95-61a2-4497-9cb9-23561037bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "200e9106-8532-4e05-b4d3-326647bb7372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16495451-8f76-4ca0-bf96-fed8fe6cc7fd",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e673f7-a80e-4208-ae32-57ca94700d9c",
   "metadata": {},
   "source": [
    "The data is normalized as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b587bcdf-bf5b-48dd-b6ee-9f507fac3619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kp['KEY_POINT_normalized'] = df_kp['KEY_POINT'].str.strip().str.replace('\\n', ' ').str.replace('\\r', ' ').str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762de105-d65b-4d4b-8ce0-82bec323e989",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "37d5181b-0c21-4380-a5a0-e697d4c2369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum tokenized input length: 65\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer(\n",
    "    df_kp_labeled['KEY_POINT_normalized'].tolist(),\n",
    "    padding=False,\n",
    "    truncation=False,\n",
    "    return_tensors=None\n",
    ")\n",
    "\n",
    "# Calc max length\n",
    "lengths = [len(input_ids) for input_ids in tokenized['input_ids']]\n",
    "max_length = max(lengths)\n",
    "print(f\"Maximum tokenized input length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25c2f87c-81ab-4e4c-9e9b-fe6dd2838c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ea9e2aec0449bc9e20f00ea7b9c05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           input_ids  \\\n",
      "0  [101, 6911, 27674, 2013, 1996, 3571, 1997, 429...   \n",
      "1  [101, 2025, 8317, 2135, 4810, 2000, 6133, 2107...   \n",
      "2  [101, 2025, 8317, 2135, 4810, 2000, 6133, 2122...   \n",
      "3  [101, 7458, 3949, 2001, 2464, 2004, 1037, 3696...   \n",
      "4  [101, 1996, 11532, 1997, 14658, 5220, 2007, 13...   \n",
      "\n",
      "                                      attention_mask  label  ID_kp_distinct  \n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1               3  \n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...      0               5  \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...      0              11  \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1              16  \n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1              26  \n"
     ]
    }
   ],
   "source": [
    "def tokenize_fn(example):\n",
    "    return tokenizer(example[\"KEY_POINT_normalized\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "\n",
    "dataset = Dataset.from_pandas(df_kp_labeled)\n",
    "\n",
    "df_tokenized = dataset.map(tokenize_fn, batched=True)\n",
    "df_tokenized_pd = df_tokenized.to_pandas()\n",
    "df_tokenized_pd['label'] = df_tokenized_pd['label'].astype(int)\n",
    "\n",
    "df_tokenized_pd = df_tokenized_pd[['input_ids', 'attention_mask', 'label', 'ID_kp_distinct']]\n",
    "print(df_tokenized_pd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f73dac0f-f864-4272-9bf4-2617d5371e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID_kp', 'ID_dta', 'KEY_POINT', 'KEY_POINT_normalized', 'ID_kp_distinct', 'label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "[1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(df_tokenized.column_names)\n",
    "print(df_tokenized['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c40defd-44da-4030-ba59-8025fbfd86b3",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8de08e2f-1cff-409b-b83b-b03e0d632ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID_kp': 6, 'ID_dta': 50, 'KEY_POINT': 'Stress stemmed from the fear of disease progression or worsening over time.', 'KEY_POINT_normalized': 'stress stemmed from the fear of disease progression or worsening over time.', 'ID_kp_distinct': 3, 'label': 1}\n",
      "\n",
      "\n",
      "{'ID_kp': 6, 'ID_dta': 50, 'KEY_POINT': 'Stress stemmed from the fear of disease progression or worsening over time.', 'KEY_POINT_normalized': 'stress stemmed from the fear of disease progression or worsening over time.', 'ID_kp_distinct': 3, 'label': 1, 'input_ids': [101, 6911, 27674, 2013, 1996, 3571, 1997, 4295, 14967, 2030, 4788, 5582, 2058, 2051, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "print(\"\\n\")\n",
    "print(df_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a93b1a0a-dbbf-4790-83d3-7b613a45c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID_kp': 8, 'ID_dta': 50, 'KEY_POINT': ' Not psychologically prepared to manage such socially awkward situations.', 'KEY_POINT_normalized': 'not psychologically prepared to manage such socially awkward situations.', 'ID_kp_distinct': 5, 'label': 0}\n",
      "\n",
      "\n",
      "{'ID_kp': 8, 'ID_dta': 50, 'KEY_POINT': ' Not psychologically prepared to manage such socially awkward situations.', 'KEY_POINT_normalized': 'not psychologically prepared to manage such socially awkward situations.', 'ID_kp_distinct': 5, 'label': 0, 'input_ids': [101, 2025, 8317, 2135, 4810, 2000, 6133, 2107, 14286, 9596, 8146, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])\n",
    "print(\"\\n\")\n",
    "print(df_tokenized[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28eb69b-350e-4be3-bdc3-98925c2afc23",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0845703-b3b1-402e-a3a8-03e6b1ecf38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6a4ce03-c843-4582-b115-35e0cb45e723",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a15c7f3-d547-4dfb-b674-76cba957bb5e",
   "metadata": {},
   "source": [
    "## Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1d359200-63f8-4be2-934d-5e7356fef1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the column names of the dataset\n",
    "df_tokenized['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "486443da-34dd-4455-b821-465f2509f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df_tokenized_pd,\n",
    "    test_size=0.8,\n",
    "    stratify=df_tokenized_pd['label'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b26f80-c1bb-4434-9c0d-6414a82b9913",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b414c706-5404-4916-b3fd-3e4de9101ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/base_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=1,\n",
    "    save_steps=1,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=0,\n",
    "    load_best_model_at_end=True,\n",
    "    gradient_accumulation_steps=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "85d79fd2-eb10-4bf0-8436-3fd7a9af0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7e104432-161b-4149-b7c7-337ee8991f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\Desktop\\School\\MaStat\\Master\\envs\\env_thesis_39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.328800</td>\n",
       "      <td>0.686376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.310100</td>\n",
       "      <td>0.691823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297700</td>\n",
       "      <td>0.689448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.234800</td>\n",
       "      <td>0.683872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.680028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.677546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.207300</td>\n",
       "      <td>0.675979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.214300</td>\n",
       "      <td>0.673962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>0.672942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>0.672157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\Desktop\\School\\MaStat\\Master\\envs\\env_thesis_39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Gebruiker\\Desktop\\School\\MaStat\\Master\\envs\\env_thesis_39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Gebruiker\\Desktop\\School\\MaStat\\Master\\envs\\env_thesis_39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Gebruiker\\Desktop\\School\\MaStat\\Master\\envs\\env_thesis_39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Gebruiker\\Desktop\\School\\MaStat\\Master\\envs\\env_thesis_39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Gebruiker\\Desktop\\School\\MaStat\\Master\\envs\\env_thesis_39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Gebruiker\\Desktop\\School\\MaStat\\Master\\envs\\env_thesis_39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Gebruiker\\Desktop\\School\\MaStat\\Master\\envs\\env_thesis_39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\Gebruiker\\Desktop\\School\\MaStat\\Master\\envs\\env_thesis_39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=0.25509653687477113, metrics={'train_runtime': 92.0937, 'train_samples_per_second': 0.326, 'train_steps_per_second': 0.109, 'total_flos': 986666457600.0, 'train_loss': 0.25509653687477113, 'epoch': 10.0})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca0366-51f9-43ad-9779-d3e09066fd66",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "844f5d4f-eb64-4950-b02a-b45071459168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\Desktop\\School\\MaStat\\Master\\envs\\env_thesis_39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 0 1 1 1]\n",
      "[1 1 0 0 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "predicted_logits = predictions.predictions\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "predicted_labels = np.argmax(predicted_logits, axis=-1)\n",
    "print(predicted_labels[:10])\n",
    "print(true_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2f16d4af-8576-4bcf-84fa-806c388cce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap 95% CI for accuracy: [0.83333333 0.83333333]\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([0, 0, 1, 0, 1, 1])\n",
    "y_pred = np.array([0, 0, 1, 0, 1, 0])\n",
    "\n",
    "n = len(y_true)\n",
    "n_bootstraps = 1000\n",
    "accuracies = []\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    idx = np.random.choice(n, size=n, replace=True)\n",
    "    acc = np.mean(y_true[idx] == y_pred[idx])\n",
    "    accuracies.append(acc)\n",
    "\n",
    "conf_int = np.percentile(accuracies, [45, 55])\n",
    "print(\"Bootstrap 95% CI for accuracy:\", conf_int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d07a6c-7aa1-45b8-a0ec-835f46e4a770",
   "metadata": {},
   "source": [
    "# Semi-Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d47f7-c62d-45cb-8417-c9d03f12d386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0bb79-158d-4608-8263-f8fe2cd23b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_thesis_39",
   "language": "python",
   "name": "env_thesis_39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
